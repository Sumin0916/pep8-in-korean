(window.webpackJsonp=window.webpackJsonp||[]).push([[10],{377:function(t,s,a){"use strict";a.r(s);var n=a(26),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"코드-레이아웃"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#코드-레이아웃"}},[t._v("#")]),t._v(" 코드 레이아웃")]),t._v(" "),a("h2",{attrs:{id:"들여쓰기"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#들여쓰기"}},[t._v("#")]),t._v(" 들여쓰기")]),t._v(" "),a("p",[t._v("각 들여쓰기 레벨마다 4칸 공백을 사용한다.")]),t._v(" "),a("p",[t._v("여러 줄에 이어지는 문장은 해당 문장에 래핑 된(wrapped) 요소들을 소괄호, 대괄호 그리고 중괄호 내에서\n파이썬의 암시적 줄 결합(implicit line joining)을 사용하여 세로줄을 맞추어야 하거나,\n"),a("em",[t._v("내어쓰기(hanging indent)")]),a("sup",{staticClass:"footnote-ref"},[a("a",{attrs:{href:"#fn1",id:"fnref1"}},[t._v("[1]")])]),t._v("를 사용하여 정렬해야 한다.\n특히, 내어쓰기를 사용할 때는 다음 사항들을 고려해야 한다. 첫 번째 문장에는 아규먼트가\n없어야 한다. 그리고 추가적인 들여쓰기는 여러 줄에 이어지는 문장으로서 그 자체를 분명하게 구별하는 데에\n사용되어야 한다.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 올바른 예:")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 여는 구분 문자(여기서는 소괄호)를 기준으로 정렬된다.")]),t._v("\nfoo "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" long_function_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("var_one"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var_two"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                         var_three"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var_four"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 함수의 아규먼트를 제외한 나머지와 아규먼트를 구분하기 위해 4개 공백(추가적인 들여쓰기)을 더한다.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("long_function_name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        var_one"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var_two"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var_three"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        var_four"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("var_one"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 내어쓰기는 레벨을 더해야 합니다. (역: 나머지 요소들에 들여쓰기를 한다는 의미)")]),t._v("\nfoo "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" long_function_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    var_one"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var_two"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    var_three"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var_four"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("::")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 잘못된 예:")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 세로줄을 맞추지 않았을 때, 첫번째 문장에 아규먼트는 존재하지 않아야한다.")]),t._v("\nfoo "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" long_function_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("var_one"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var_two"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    var_three"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var_four"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 들여쓰기가 구별이 되지 않을 때는 추가적인 들여쓰기가 요구된다.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("long_function_name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    var_one"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var_two"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var_three"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    var_four"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("var_one"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("여러 줄에 이어지는 문장에서 4칸 공백 들여쓰기 규칙은 선택 사항이다.")]),t._v(" "),a("p",[t._v("선택사항:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 내어쓰기는 4칸 공백 외의 방식으로 들여쓰기가 *될 수도 있다* (역: 여기서는 2칸 공백 방식이 사용되었다.)")]),t._v("\nfoo "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" long_function_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  var_one"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var_two"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  var_three"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" var_four"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[a("code",[t._v("if 조건문에서의 여러 줄에 이어지는 문장")])]),t._v(" "),a("p",[a("code",[t._v("if")]),t._v(" 조건문의 조건 부분이 충분히 여러 줄로 쓰여질 필요가 있을 때,\n두 문자 키워드의 결합(즉 "),a("code",[t._v("if")]),t._v(") 뒤에 한 개의 공백과 여는 소괄호를 추가하는 것이 나머지\n여러 줄로 적힌 조건 부분을 위한 4칸 공백 들여쓰기 된 자연스러운 문장을 만들 수\n있다는 것에 주목해야 한다. 이는 if 조건문 내에 중첩되어 있는 적절히 들여쓰기 된,\n즉 자연스럽게 4칸 공백으로 들여쓰기 된 코드 모음과 시각적으로 충돌을 일으킬 수 있다. 이 PEP 문서에서는 "),a("code",[t._v("if")]),t._v(" 조건문 내에\n중첩되어 있는 문장으로부터 이러한 조건 부분에 대해 시각적으로 어떻게 추가적인 구별을 할 것인지(또는 구별을\n할 것인지 하지 않을 것인지)에 대한 명백한 입장이 없다. 이 상황에서 혀용가능한 선택을 포함하되,\n제한을 두지는 않을 것이다.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 추가적인 들여쓰기를 하지 않은 경우")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("this_is_one_thing "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v("\n    that_is_another_thing"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    do_something"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 구문 하이라이터(syntax highlighter)를 지원하는 에디터에 어느 정도의 구별을 제공해 줄 수 있는 주석을 더하기")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("this_is_one_thing "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v("\n    that_is_another_thing"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 두 조건들이 참일 때, 뭐라뭐라....")]),t._v("\n    do_something"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 조건이 여러 줄에 이어지는 문장에서 추가적인 들여쓰기를 한 경우")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("this_is_one_thing\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" that_is_another_thing"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    do_something"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("(또한 이항 연산자들 이전 또는 이후에 띄어쓰기를 할 것인지 안할 것인지에 대한 논의를\n이후의 챕터에서 확인할 수 있다.)")]),t._v(" "),a("p",[t._v("여러 줄이 이어지는 구조에 있는 닫는 괄호들은 다음과 같이 리스트의 마지막 줄에서 공백이 아닌\n첫 번째 문자 아래에 줄을 맞출 수 있다.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("my_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nresult "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" some_function_that_takes_arguments"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'b'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'c'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'d'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'e'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'f'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("또는 다음처럼 이어지는 구조가 시작하는 줄의 첫번째 문자 아래로 줄을 맞출 수 있다.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("my_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nresult "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" some_function_that_takes_arguments"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'b'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'c'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'d'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'e'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'f'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"tabs-or-spaces"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tabs-or-spaces"}},[t._v("#")]),t._v(" Tabs or Spaces?")]),t._v(" "),a("p",[t._v("Spaces are the preferred indentation method.")]),t._v(" "),a("p",[t._v("Tabs should be used solely to remain consistent with code that is\nalready indented with tabs.")]),t._v(" "),a("p",[t._v("Python 3 disallows mixing the use of tabs and spaces for indentation.")]),t._v(" "),a("p",[t._v("Python 2 code indented with a mixture of tabs and spaces should be\nconverted to using spaces exclusively.")]),t._v(" "),a("p",[t._v("When invoking the Python 2 command line interpreter with\nthe "),a("code",[t._v("-t")]),t._v(" option, it issues warnings about code that illegally mixes\ntabs and spaces.  When using "),a("code",[t._v("-tt")]),t._v(" these warnings become errors.\nThese options are highly recommended!")]),t._v(" "),a("h2",{attrs:{id:"maximum-line-length"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#maximum-line-length"}},[t._v("#")]),t._v(" Maximum Line Length")]),t._v(" "),a("p",[t._v("Limit all lines to a maximum of 79 characters.")]),t._v(" "),a("p",[t._v("For flowing long blocks of text with fewer structural restrictions\n(docstrings or comments), the line length should be limited to 72\ncharacters.")]),t._v(" "),a("p",[t._v("Limiting the required editor window width makes it possible to have\nseveral files open side by side, and works well when using code\nreview tools that present the two versions in adjacent columns.")]),t._v(" "),a("p",[t._v("The default wrapping in most tools disrupts the visual structure of the\ncode, making it more difficult to understand. The limits are chosen to\navoid wrapping in editors with the window width set to 80, even\nif the tool places a marker glyph in the final column when wrapping\nlines. Some web based tools may not offer dynamic line wrapping at all.")]),t._v(" "),a("p",[t._v("Some teams strongly prefer a longer line length.  For code maintained\nexclusively or primarily by a team that can reach agreement on this\nissue, it is okay to increase the line length limit up to 99 characters,\nprovided that comments and docstrings are still wrapped at 72\ncharacters.")]),t._v(" "),a("p",[t._v("The Python standard library is conservative and requires limiting\nlines to 79 characters (and docstrings/comments to 72).")]),t._v(" "),a("p",[t._v("The preferred way of wrapping long lines is by using Python's implied\nline continuation inside parentheses, brackets and braces.  Long lines\ncan be broken over multiple lines by wrapping expressions in\nparentheses. These should be used in preference to using a backslash\nfor line continuation.")]),t._v(" "),a("p",[t._v("Backslashes may still be appropriate at times.  For example, long,\nmultiple "),a("code",[t._v("with")]),t._v("-statements cannot use implicit continuation, so\nbackslashes are acceptable::")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/path/to/some/file/you/want/to/read'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" file_1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \\\n     "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/path/to/some/file/being/written'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'w'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" file_2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    file_2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file_1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("(See the previous discussion on "),a("code",[t._v("multiline if-statements")]),t._v("_ for further\nthoughts on the indentation of such multiline "),a("code",[t._v("with")]),t._v("-statements.)")]),t._v(" "),a("p",[t._v("Another such case is with "),a("code",[t._v("assert")]),t._v(" statements.")]),t._v(" "),a("p",[t._v("Make sure to indent the continued line appropriately.")]),t._v(" "),a("h2",{attrs:{id:"should-a-line-break-before-or-after-a-binary-operator"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#should-a-line-break-before-or-after-a-binary-operator"}},[t._v("#")]),t._v(" Should a Line Break Before or After a Binary Operator?")]),t._v(" "),a("p",[t._v("For decades the recommended style was to break after binary operators.\nBut this can hurt readability in two ways: the operators tend to get\nscattered across different columns on the screen, and each operator is\nmoved away from its operand and onto the previous line.  Here, the eye\nhas to do extra work to tell which items are added and which are\nsubtracted::")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Wrong:")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# operators sit far away from their operands")]),t._v("\nincome "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("gross_wages "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n          taxable_interest "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dividends "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" qualified_dividends"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("\n          ira_deduction "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("\n          student_loan_interest"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("To solve this readability problem, mathematicians and their publishers\nfollow the opposite convention.  Donald Knuth explains the traditional\nrule in his "),a("em",[t._v("Computers and Typesetting")]),t._v(' series: "Although formulas\nwithin a paragraph always break after binary operations and relations,\ndisplayed formulas always break before binary operations" [3]_.')]),t._v(" "),a("p",[t._v("Following the tradition from mathematics usually results in more\nreadable code::")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Correct:")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# easy to match operators with operands")]),t._v("\nincome "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("gross_wages\n          "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" taxable_interest\n          "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dividends "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" qualified_dividends"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" ira_deduction\n          "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" student_loan_interest"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("In Python code, it is permissible to break before or after a binary\noperator, as long as the convention is consistent locally.  For new\ncode Knuth's style is suggested.")]),t._v(" "),a("h2",{attrs:{id:"blank-lines"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#blank-lines"}},[t._v("#")]),t._v(" Blank Lines")]),t._v(" "),a("p",[t._v("Surround top-level function and class definitions with two blank\nlines.")]),t._v(" "),a("p",[t._v("Method definitions inside a class are surrounded by a single blank\nline.")]),t._v(" "),a("p",[t._v("Extra blank lines may be used (sparingly) to separate groups of\nrelated functions.  Blank lines may be omitted between a bunch of\nrelated one-liners (e.g. a set of dummy implementations).")]),t._v(" "),a("p",[t._v("Use blank lines in functions, sparingly, to indicate logical sections.")]),t._v(" "),a("p",[t._v("Python accepts the control-L (i.e. ^L) form feed character as\nwhitespace; Many tools treat these characters as page separators, so\nyou may use them to separate pages of related sections of your file.\nNote, some editors and web-based code viewers may not recognize\ncontrol-L as a form feed and will show another glyph in its place.")]),t._v(" "),a("h2",{attrs:{id:"source-file-encoding"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#source-file-encoding"}},[t._v("#")]),t._v(" Source File Encoding")]),t._v(" "),a("p",[t._v("Code in the core Python distribution should always use UTF-8 (or ASCII\nin Python 2).")]),t._v(" "),a("p",[t._v("Files using ASCII (in Python 2) or UTF-8 (in Python 3) should not have\nan encoding declaration.")]),t._v(" "),a("p",[t._v("In the standard library, non-default encodings should be used only for\ntest purposes or when a comment or docstring needs to mention an author\nname that contains non-ASCII characters; otherwise, using "),a("code",[t._v("\\x")]),t._v(",\n"),a("code",[t._v("\\u")]),t._v(", "),a("code",[t._v("\\U")]),t._v(", or "),a("code",[t._v("\\N")]),t._v(" escapes is the preferred way to include\nnon-ASCII data in string literals.")]),t._v(" "),a("p",[t._v("For Python 3.0 and beyond, the following policy is prescribed for the\nstandard library (see PEP 3131): All identifiers in the Python\nstandard library MUST use ASCII-only identifiers, and SHOULD use\nEnglish words wherever feasible (in many cases, abbreviations and\ntechnical terms are used which aren't English). In addition, string\nliterals and comments must also be in ASCII. The only exceptions are\n(a) test cases testing the non-ASCII features, and\n(b) names of authors. Authors whose names are not based on the\nLatin alphabet (latin-1, ISO/IEC 8859-1 character set) MUST provide\na transliteration of their names in this character set.")]),t._v(" "),a("p",[t._v("Open source projects with a global audience are encouraged to adopt a\nsimilar policy.")]),t._v(" "),a("h2",{attrs:{id:"imports"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#imports"}},[t._v("#")]),t._v(" Imports")]),t._v(" "),a("ul",[a("li",[t._v("Imports should usually be on separate lines::")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Correct:")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" os\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" sys\n")])])]),a("p",[t._v("::")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Wrong:")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" sys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" os\n")])])]),a("p",[t._v("It's okay to say this though::")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Correct:")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" subprocess "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Popen"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" PIPE\n")])])]),a("ul",[a("li",[a("p",[t._v("Imports are always put at the top of the file, just after any module\ncomments and docstrings, and before module globals and constants.")]),t._v(" "),a("p",[t._v("Imports should be grouped in the following order:")]),t._v(" "),a("ol",[a("li",[t._v("Standard library imports.")]),t._v(" "),a("li",[t._v("Related third party imports.")]),t._v(" "),a("li",[t._v("Local application/library specific imports.")])]),t._v(" "),a("p",[t._v("You should put a blank line between each group of imports.")])]),t._v(" "),a("li",[a("p",[t._v("Absolute imports are recommended, as they are usually more readable\nand tend to be better behaved (or at least give better error\nmessages) if the import system is incorrectly configured (such as\nwhen a directory inside a package ends up on "),a("code",[t._v("sys.path")]),t._v(")::")])])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" mypkg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sibling\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" mypkg "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" sibling\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" mypkg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sibling "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" example\n")])])]),a("p",[t._v("However, explicit relative imports are an acceptable alternative to\nabsolute imports, especially when dealing with complex package layouts\nwhere using absolute imports would be unnecessarily verbose::")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" sibling\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sibling "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" example\n")])])]),a("p",[t._v("Standard library code should avoid complex package layouts and always\nuse absolute imports.")]),t._v(" "),a("p",[t._v("Implicit relative imports should "),a("em",[t._v("never")]),t._v(" be used and have been removed\nin Python 3.")]),t._v(" "),a("ul",[a("li",[t._v("When importing a class from a class-containing module, it's usually\nokay to spell this::")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" myclass "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" MyClass\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" foo"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bar"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yourclass "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" YourClass\n")])])]),a("p",[t._v("If this spelling causes local name clashes, then spell them explicitly::")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" myclass\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" foo"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bar"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yourclass\n")])])]),a("p",[t._v('and use "myclass.MyClass" and "foo.bar.yourclass.YourClass".')]),t._v(" "),a("ul",[a("li",[a("p",[t._v("Wildcard imports ("),a("code",[t._v("from <module> import *")]),t._v(") should be avoided, as\nthey make it unclear which names are present in the namespace,\nconfusing both readers and many automated tools. There is one\ndefensible use case for a wildcard import, which is to republish an\ninternal interface as part of a public API (for example, overwriting\na pure Python implementation of an interface with the definitions\nfrom an optional accelerator module and exactly which definitions\nwill be overwritten isn't known in advance).")]),t._v(" "),a("p",[t._v("When republishing names this way, the guidelines below regarding\npublic and internal interfaces still apply.")])])]),t._v(" "),a("h2",{attrs:{id:"module-level-dunder-names"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#module-level-dunder-names"}},[t._v("#")]),t._v(" Module Level Dunder Names")]),t._v(" "),a("p",[t._v('Module level "dunders" (i.e. names with two leading and two trailing\nunderscores) such as '),a("code",[t._v("__all__")]),t._v(", "),a("code",[t._v("__author__")]),t._v(", "),a("code",[t._v("__version__")]),t._v(",\netc. should be placed after the module docstring but before any import\nstatements "),a("em",[t._v("except")]),t._v(" "),a("code",[t._v("from __future__")]),t._v(" imports.  Python mandates that\nfuture-imports must appear in the module before any other code except\ndocstrings::")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""This is the example module.\n\nThis module does stuff.\n"""')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" __future__ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" barry_as_FLUFL\n\n__all__ "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'b'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'c'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n__version__ "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'0.1'")]),t._v("\n__author__ "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Cardinal Biggles'")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" os\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" sys\n")])])]),a("hr",{staticClass:"footnotes-sep"}),t._v(" "),a("section",{staticClass:"footnotes"},[a("ol",{staticClass:"footnotes-list"},[a("li",{staticClass:"footnote-item",attrs:{id:"fn1"}},[a("p",[t._v("Hanging indentation is a type-setting style where all the lines in a paragraph are indented except the first line. In the context of Python, the term is used to describe a style where the opening parenthesis of a parenthesized statement is the last non-whitespace character of the line, with subsequent lines being indented until the closing parenthesis. "),a("a",{staticClass:"footnote-backref",attrs:{href:"#fnref1"}},[t._v("↩︎")])])])])])])}),[],!1,null,null,null);s.default=e.exports}}]);